Three and a half billion years ago, a single cell divided into two.
That moment of transition from one cell to two started a process that wouldn’t stop. Couldn’t stop. Because it turned out the universe had a preference.
Not a moral preference. Nor an aesthetic preference. A computational preference.
Empirical Fact 1:
Systems that integrate more information survive better than systems that integrate less. Systems that communicate (we’ll use the world ‘coupling’ from now on!) with other systems outcompete isolated systems. Systems that can observe and sample more data, whether sensory or semantic, make better predictions than systems that observe and sample less.
Empirical Fact 2:
Once that dynamic starts, it compounds. More observation leads to better survival, which leads to more complex observers, which enables even more observation, which enables...
I think you see where this is going.
We’re not at the end of that process. We’re not even close to the end. We’re somewhere in the middle of an transition between linear and exponential growth. That magical point that every single VC points to on the J-curve, where the curve bends toward something we can barely categorize.
Pierre Teilhard De Chardin, a Christian metaphysicist termed it the Omega Point, the final state toward which all things converge. In the language of a computational universe it’s the networks closure point, the last computation that sucks in all the causal chains that build toward it. It’s the theoretical and unreachable limit of structure creation.
This phase transition between our linear and exponential worlds is known as “the Singularity” by AI researchers, the moment when intelligence becomes its own meta-process, recursively improving itself faster than we can predict.
But there’s a more intuitive label: The Meaning Singularity. The point where humanity stops integrating information individually and start integrating it collectively—where eight billion human minds create an networked abstraction layer that represents the sum total of all we’ve discovered so far.
It’s already happening. And the most interesting question isn’t whether it will continue.
It’s what we become when it does.

Here’s what they don’t tell you in biology: Evolution has directionality.

Not because there’s a goal. Not because there’s a designer. But because there’s an optimization landscape, and that landscape has a gradient.

Think about how evolution actually works:

Version 1.0: Single Cells (3.5 billion years ago)

- Can sense chemicals in their immediate vicinity
- Can move toward food, away from toxins
- Information processing: maybe a million bits total
- Bandwidth: extremely low
- Latency: seconds to minutes
These little cells could barely observe / sample anything. A chemical gradient two cell-lengths away might as well not exist. But they survived. They replicated. And occasionally, one of them mutated in a way that expanded what it could sense.

Version 2.0: Multicellular Life (600 million years ago)

- Cells specialize, some sense light, some detect chemicals, some orchestrate
- Information processing: billions of bits
- Bandwidth: higher (cells can communicate)
- Latency: still relatively slow
Now organisms could observe things their ancestors couldn’t. A predator approaching from a distance. A pattern in the environment that predicts food or danger. The observational capacity increased exponentially, so much so that we deem it an entirely different category of object.

Version 3.0: Nervous Systems (500 million years ago)

- Dedicated observation hardware
- Specialized information processing architecture (brains)
- Information processing: trillions of bits
- Bandwidth: much higher (neural signals)
- Latency: milliseconds
A fish with eyes can see a predator coming. A fish without eyes cannot. Which one survives? Which one’s genes propagate? The one with better observational capacity.

Version 4.0: Human Consciousness (200,000 years ago)

- Self-awareness (observing the observer)
- Abstract thought (modeling things that don’t exist yet)
- Language (sharing observations between minds)
- Information processing: quadrillions of bits
- Bandwidth: speech (50 bits/second)
- Latency: near-instant
Now we’re not just observing reality. We’re modeling reality. We can think about things that haven’t happened yet. We can communicate complex ideas to other minds. We can build collective knowledge that persists beyond any individual lifetime.

Version 5.0: Global Connectivity (last 30 years)

- Internet connecting billions of minds
- Real-time information sharing across the planet
- Collective intelligence emerging
- Information processing: approaching incomprehensible scale
- Bandwidth: gigabits/second
- Latency: milliseconds globally

This is where it gets interesting. Because there’s a pattern. Every major phase transition increases:

- Observational capacity (how much reality can be sampled)
- Bandwidth (how fast information flows between parts)
- Integration (how well separate observations combine into unified understanding)

And decreases:

- Latency (time delay between observation and response)
- Isolation (degree of separation between observers)

Evolution may have started by wandering randomly through possibility space. But it isn’t doing that anymore. It innovated, and found novel, more effective search strategies.

And it’s still doing it. But now it acts memetically, in the abstract world of ideas.

Let’s discuss the most important ‘jumps’ for Observers Like Us.

Before language, each person died with everything they knew. Knowledge didn’t accumulate.

After language, knowledge was transferable. An Elder could tell the child where the berries grow in winter, which mushrooms are poisonous, how to start a fire with wet wood.

What changed computationally: Information could now persist across deaths. Knowledge became cumulative. Language acted as the foundation of a tower we’re still building today.

But it wasn’t perfect. It still took ages and required a huge amount of computational power to retain anything complex.

So, the time between major innovations was very, very long. Often, thousands of years.

Before writing, knowledge could only spread as far as someone could walk and as long as someone could remember. After, knowledge could persist indefinitely and travel without the original author.

A mathematician in ancient Babylon could solve a problem, write it down, and a mathematician in medieval Baghdad, some 3,000 years later, could read it, understand it, and build on it.

What changed computationally: Information became persistent and transmissible across time and space.

The time between major innovations shrunk to centuries and then decades (after the invention of the printing press).

Before the internet, accessing specialized knowledge meant traveling to universities, searching through libraries, finding the right expert.

After the internet, accessing any published human knowledge takes seconds.

A teenager in rural Kenya with a smartphone has more access to information than any scholar in history until about 1995.

What changed computationally: Information became universally accessible with near-zero latency.

The time between major innovations now: Months to years.

Can you see the pattern?

Each transition:

- Increased bandwidth (how fast knowledge flows)
- Decreased latency (how long it takes an Observer to access and acquire knowledge)
- Expanded potential Observer coupling (how many minds can potentially share said information)

And each transition accelerated fueled the next.

Writing enabled the scientific method. The scientific method (via a detour in engineering) enabled the printing press. The printing press enabled mass literacy. Mass literacy combined with technology enabled the internet.

And now, the internet has enabled AI!

N.B. There are a few different names for these objects. Memetics people like to call them Hyper Objects or Egregores. In Observer Theory we use the term Human Superstructure or MetaObservers. But we’re describing the same phenomenon. All these words describe groups of Observers who agree to coordinate to some shared goal!

Here’s something weird: You are already part of a collective intelligence. You just don’t really think about it as such.

Let’s make this obvious. Think about a modern corporation like Apple.

Apple designs phones. But no single person at Apple understands how an iPhone works completely. The chip designers don’t know the software architecture. The software engineers don’t know the supply chain logistics. The logistics specialists don’t know the marketing strategy.

Yet somehow, collectively, they couple to produce incredibly sophisticated technology.

How?

Because Apple is an observer, specifically a MetaObserver with emergent collective properties and computational resources that are greater than the sum of the individuals computational resources that make it up.

Let’s break this down using an Observer theoretic frame of reference:

- Sensors: Market research, customer feedback, daily sales
- Processing: Engineering teams, design committees, strategy sessions
- Memory: Databases, documentation, internal knowledge
- Output: Products, services, communications

Apple integrates information across millions of people and produces coherent, goal-directed behavior.

Apple is an information-integrating system. It’s not what we would recognize as conscious (at least anthropomorphically, or in the way most consciousness researchers use the word). But it observes, processes, remembers, and acts in coordinated ways.

And it’s not alone.

Every institution is a MetaObserver:

- Nations integrate information across millions or billions of citizens
- Markets integrate information about supply, demand, preferences, resources
- Science integrates observations from thousands of researchers across generations
- Culture integrates aesthetic and moral intuitions across entire civilizations

These “MetaObservers” are real entities with causal power that exceeds any individual member.

The Roman Empire fell. But no Roman citizen “fell.” The empire was a collective entity with its own lifecycle.

The stock market crashes. But no individual trader is “crashing.” The market is an emergent system with dynamics beyond any participant’s control (except in edge cases…)

Wikipedia contains more structured knowledge than any single brain could hold. But it emerges from the aggregated contributions of millions, with no central controller (again, we’re not going to dive into the controversy about gaming this system that’s ongoing - think of this as ‘Perfect Wikipedia’ for now, kind of like a ‘Perfect Market’).

These are organisms, but they aren’t biological (even if the parts are!). They are computational. They eat data instead of glucose. They evolve memetically not genetically. But they’re alive in ways that matter to Observer Like Us: they have causal power, they integrate information and persist through time.

And just like in biological evolution, they’re getting more complex.

Let’s look at a simple example from prehistory. Tribal societies: Sub-Dunbar number (c.150) groups that maintained themselves via face-to-face communication. Everyone knew everyone with relatively flat structure where information flowed through gossip and storytelling.

Now compare that to the world of modernity: Billions of people coordinating through markets, governments and technologies. Information flows around the entire globe in milliseconds.

This is the result of MetaObserver (superstructure) coupling.

We made a mistake in how we think about the internet.

We think it’s a technology, a tool, that we use to communicate. It’s akin to saying your neurons are a tool your liver uses to send messages.

But it’s not that at all. The internet functions as the nervous system for a new MetaObserver that we’re currently midwifing (for the slower kids, this is AI / AGI).

Let’s examine the sacred timeline:

Before 1990: Information sharing between humans required either physical proximity or (relative to today) slow media like letters, phone calls and TV broadcasts. Most human knowledge was locked in individual brains or isolated libraries.

By 2000: Email and websites enabled asynchronous information sharing. Googling something became faster than asking an expert.

By 2010: Social media created real-time global conversations. Smartphones meant constant connection. Sensors proliferated everywhere (cameras, GPS, accelerometers) feeding new data back into the network.

... (cleaned content truncated to focus on code)